{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim.models as g\n",
    "import jieba\n",
    "import re\n",
    "jieba.add_word(\"马嘉祺公益祺迹\",True)\n",
    "jieba.add_word(\"新型冠状病毒\",True)\n",
    "stop_word_list = [\"是\", \"的\" ,\"因为\",\"了\",\"也\"]\n",
    "    \n",
    "def read_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    y_map = {\"happy\":1 , \"sad\" :2 , \"angry\" : 3 , \"neural\" : 4, \"fear\" : 5 , \"surprise\" : 6}\n",
    "    with open(\"virus_train.txt\",\"r\",encoding=\"utf-8\") as f: \n",
    "        data = f.read()\n",
    "    data = json.loads(data)\n",
    "    for i in data:\n",
    "        temp_x = []\n",
    "        s = re.sub(\"//@.*?:\",\"\", i[\"content\"])\n",
    "        s = re.sub(\"(ht|f)tp(s?)\\:\\/\\/[0-9a-zA-Z]([-.\\w]*[0-9a-zA-Z])*(:(0-9)*)*(\\/?)([a-zA-Z0-9\\-\\.\\?\\,\\'\\/\\\\\\+&amp;%$#_]*)?\",\"\",s)\n",
    "        s = re.sub(\"[\\[\\]_.!！+-=——,$%·^『』～；\\\"，“”。?？＋、： ％~@#￥%……&*《》<>「」{}【】()/]\",\"\",s)\n",
    "        segment_list = jieba.cut(s,cut_all=False)\n",
    "        \n",
    "        segment = \",\".join(segment_list)\n",
    "        if s is None:\n",
    "            continue\n",
    "        x.append(segment.split(\",\"))\n",
    "        y.append(y_map[i[\"label\"]])\n",
    "    return  x , y\n",
    "x , y = read_data()\n",
    "# print(x,y)\n",
    "# print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def gensim_test():\n",
    "    model = g.Word2Vec(x,min_count=3,vector_size=100)\n",
    "    print(model)\n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "word2vec = g.Word2Vec(x, \n",
    "                       vector_size=100,   # 词向量维度\n",
    "                       min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                       epochs=100) \n",
    "\n",
    "# print(word2vec.wv.most_similar(\"武汉\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "[('湖北', 0.4733487367630005),\n ('在', 0.4005740284919739),\n ('的', 0.3984314799308777),\n ('我们', 0.39034581184387207),\n ('了', 0.35161668062210083),\n ('都', 0.34879183769226074),\n ('病例', 0.34381434321403503),\n ('海南', 0.3384853005409241),\n ('你', 0.3307299315929413),\n ('也', 0.32444286346435547)]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 162
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"武汉\")\n",
    "# word2vec.wv.most_similar(\"天使\")\n",
    "# for i ,v in word2vec.wv.key_to_index.items():\n",
    "#     print(i,v  )\n",
    "# word2vec.wv[\"的\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "武汉正在玩儿命求援请求民间援助新闻联播在播这个我不是武汉人看了都有点生气武汉人应该在家骂大街吧 \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "a = \"//@这瓜沙沙雕雕的保甜://@菜刀曦曦:武汉正在玩儿命求援，请求民间援助。新闻联播在播这个。我不是武汉人看了都有点生气。武汉人应该在家骂大街吧。 http://t.cn/A6PZCMJS\"\n",
    "s = re.sub(\"//@.*?:\",\"\"  , a)\n",
    "s = re.sub(\"(ht|f)tp(s?)\\:\\/\\/[0-9a-zA-Z]([-\\\".\\w]*[0-9a-zA-Z])*(:(0-9)*)*(\\/?)([a-zA-Z0-9\\-\\.\\?\\,\\'\\/\\\\\\+&amp;%$#_]*)?\",\"\",s)\n",
    "s = re.sub(\"[\\[\\]\\|_.→!+-=——,$%^，（～；。）？、~@#￥%……&*《》<>「」{}【】()/]\",\"\",s)\n",
    "print(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "{'呢': 0,\n '你是什么人': 1,\n '我是中国人': 2,\n '狗': 3,\n '猫': 4,\n '玩儿命求援': 5,\n '你是谁啊': 6,\n '哈哈': 7}"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 127
    }
   ],
   "source": [
    "a = [[\"哈哈\"],[\"你是谁啊\",\"玩儿命求援\",\"猫\", \"狗\"],[\"我是中国人\"],[\"你是什么人\",\"呢\"]]\n",
    "word2vec = g.Word2Vec(a, \n",
    "                   vector_size=64,   # 词向量维度\n",
    "                   min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                   epochs=1) \n",
    "word2vec.wv.most_similar(\"猫\")\n",
    "word2vec.wv.key_to_index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}