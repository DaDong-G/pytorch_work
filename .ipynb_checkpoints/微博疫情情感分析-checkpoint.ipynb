{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim.models as g\n",
    "import jieba\n",
    "import re\n",
    "import torch\n",
    "jieba.add_word(\"马嘉祺公益祺迹\",True)\n",
    "jieba.add_word(\"新型冠状病毒\",True)\n",
    "stop_word_list = [\"是\", \"的\" ,\"因为\",\"了\",\"也\"]\n",
    "    \n",
    "def read_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    y_map = {\"happy\":0 , \"sad\" :1 , \"angry\" : 2 , \"neural\" : 3, \"fear\" : 4 , \"surprise\" : 5}\n",
    "    with open(\"virus_train.txt\",\"r\",encoding=\"utf-8\") as f: \n",
    "        data = f.read()\n",
    "    data = json.loads(data)\n",
    "    for i in data:\n",
    "        temp_x = []\n",
    "        s = re.sub(\"//@.*?:\",\"\", i[\"content\"])\n",
    "        s = re.sub(\"(ht|f)tp(s?)\\:\\/\\/[0-9a-zA-Z]([-.\\w]*[0-9a-zA-Z])*(:(0-9)*)*(\\/?)([a-zA-Z0-9\\-\\.\\?\\,\\'\\/\\\\\\+&amp;%$#_]*)?\",\"\",s)\n",
    "        s = re.sub(\"[\\[\\]_.!！+-=——,$%·^『』～；\\\"，“”。?？＋、： ％~@#￥%……&*《》<>「」{}【】()/]\",\"\",s)\n",
    "        segment_list = jieba.cut(s,cut_all=False)\n",
    "        \n",
    "        segment = \",\".join(segment_list)\n",
    "        if s is None:\n",
    "            continue\n",
    "        x.append(segment.split(\",\"))\n",
    "        y.append(y_map[i[\"label\"]])\n",
    "    return  x , y\n",
    "x , y = read_data()\n",
    "# print(x,y)\n",
    "# print(len(x),len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def gensim_test():\n",
    "    model = g.Word2Vec(x,min_count=3,vector_size=100)\n",
    "    print(model)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "word2vec = g.Word2Vec(x, \n",
    "                       vector_size=100,   # 词向量维度\n",
    "                       min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                       epochs=100) \n",
    "\n",
    "# print(word2vec.wv.most_similar(\"武汉\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('湖北', 0.4733487367630005),\n",
       " ('在', 0.4005740284919739),\n",
       " ('的', 0.3984314799308777),\n",
       " ('我们', 0.39034581184387207),\n",
       " ('了', 0.35161668062210083),\n",
       " ('都', 0.34879183769226074),\n",
       " ('病例', 0.34381434321403503),\n",
       " ('海南', 0.3384853005409241),\n",
       " ('你', 0.3307299315929413),\n",
       " ('也', 0.32444286346435547)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"武汉\")\n",
    "# word2vec.wv.most_similar(\"天使\")\n",
    "# for i ,v in word2vec.wv.key_to_index.items():\n",
    "#     print(i,v  )\n",
    "# word2vec.wv[\"的\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "武汉正在玩儿命求援请求民间援助新闻联播在播这个我不是武汉人看了都有点生气武汉人应该在家骂大街吧 \n"
     ]
    }
   ],
   "source": [
    "a = \"//@这瓜沙沙雕雕的保甜://@菜刀曦曦:武汉正在玩儿命求援，请求民间援助。新闻联播在播这个。我不是武汉人看了都有点生气。武汉人应该在家骂大街吧。 http://t.cn/A6PZCMJS\"\n",
    "s = re.sub(\"//@.*?:\",\"\"  , a)\n",
    "s = re.sub(\"(ht|f)tp(s?)\\:\\/\\/[0-9a-zA-Z]([-\\\".\\w]*[0-9a-zA-Z])*(:(0-9)*)*(\\/?)([a-zA-Z0-9\\-\\.\\?\\,\\'\\/\\\\\\+&amp;%$#_]*)?\",\"\",s)\n",
    "s = re.sub(\"[\\[\\]\\|_.→!+-=——,$%^，（～；。）？、~@#￥%……&*《》<>「」{}【】()/]\",\"\",s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'呢': 0,\n",
       " '你是什么人': 1,\n",
       " '我是中国人': 2,\n",
       " '狗': 3,\n",
       " '猫': 4,\n",
       " '玩儿命求援': 5,\n",
       " '你是谁啊': 6,\n",
       " '哈哈': 7}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[\"哈哈\"],[\"你是谁啊\",\"玩儿命求援\",\"猫\", \"狗\"],[\"我是中国人\"],[\"你是什么人\",\"呢\"]]\n",
    "word2vec = g.Word2Vec(a, \n",
    "                   vector_size=64,   # 词向量维度\n",
    "                   min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                   epochs=1) \n",
    "word2vec.wv.most_similar(\"猫\")\n",
    "word2vec.wv.key_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "label = y\n",
    "for s in x:\n",
    "    vectors = []\n",
    "    for w in s:\n",
    "        if w in word2vec.wv.key_to_index:\n",
    "            vectors.append(word2vec.wv[w])   # 将每个词替换为对应的词向量\n",
    "    vectors = torch.Tensor(vectors)\n",
    "    datas.append(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0853, -0.2979,  0.4590,  0.8275, -0.5824, -0.4317,  0.2538,  0.8473,\n",
      "         -0.0568, -0.0291,  0.2490,  0.5803, -0.6681, -0.1134, -0.0641, -0.0028,\n",
      "         -0.0099, -1.2011,  0.2255, -0.7113, -0.5270, -0.3976,  0.4091, -0.1563,\n",
      "         -0.2495,  0.0929,  0.0477,  0.8313, -0.1585,  0.5105,  0.3892, -1.0207,\n",
      "         -0.2668,  1.1675,  0.2740,  0.7508,  0.8891,  0.1973, -1.0282, -0.3443,\n",
      "         -0.4336, -0.7978,  0.4901, -0.5758, -0.1686,  0.5021, -0.0823, -0.2187,\n",
      "          0.5912,  0.2249,  0.5461,  0.5830,  1.4706,  0.5369,  0.0730, -0.0960,\n",
      "         -0.2977,  0.1766, -0.3751, -0.4825, -0.9628,  0.2656,  0.3754, -1.0157,\n",
      "         -1.1139,  1.2287, -0.0026, -0.6295, -0.4363, -0.4208,  0.0589,  1.3946,\n",
      "         -0.6674, -0.4216,  0.5396, -0.4902, -0.8505,  0.5515, -0.9797,  0.4019,\n",
      "         -0.3004, -0.0912, -0.7227,  0.1316,  0.1776, -0.1480, -0.4921, -0.7364,\n",
      "          0.9426, -0.6496, -0.4540,  0.9159, -0.3692, -0.3731,  0.8016, -0.7453,\n",
      "         -0.0837, -0.2800, -0.0992,  0.6850]])\n"
     ]
    }
   ],
   "source": [
    "for i in datas:\n",
    "    print(i.shaoe)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "print(datas[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
